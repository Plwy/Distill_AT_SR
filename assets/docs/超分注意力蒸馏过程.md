# 基于注意力蒸馏的超分网络

​	通过将文本检测的知识蒸馏到超分网络，提升超分网络对场景文字图片的超分效果，从而提升文本检测的效果。

**设计思想：**

将文字检测的中间层特征得到的空间注意力特征图，通过知识蒸馏的方法，指导超分网络的训练。

**网络结构：**





## 教师网络与学生网络



###  教师网络（CRAFT：字符位置可感知的文本检测）

选取原因：带预训练模型，可顺利运行，效果较好(与EAST比较)，pytorch。



#### 字符位置可感知的文本检测的CRAFT

该卷积神经网络**生成字符区域得分**和**相互关系得分**。区域得分表示给定像素是字符中心的概率，而相互关系力得分表示相邻字符之间空间的中心概率

区域分数用于在图像中定位单个字符，而相互关系分数用于将每个字符分组为一个实例。

Figure1.0 craft 网络结构

![preview](../figures/v2-5e8b96a59b4f861214839bfc8e7198f6_r.jpg)



特点：

提出的标签定义使模型能够充分检测大型或长文本实例，尽管使用的感受野较小。

使卷积滤波器可以仅关注字符内和字符间，而不关注整个文本实例。



### 学生网络（RCAN：深度残差注意力超分网络）

选取原因：目前SR网络中效果最好，且有完整代码。

Figure 1.1 RCAN网络结构

![RCAN_network](../figures/RCAN_network.png)



## 特征的选取与处理



> 选取教师网络的哪几层提取空间特征？
>
> 选取学生网络的哪几层添加空间注意力模块？
>



### 教师网络的特征空间注意力激活方法

​	该方法基于一个潜在假设，认为**隐藏层神经元激活的绝对值可以用于指示这个神经元的重要性。**

对于教师网络中间层输出的特征，使用以下公式计算。
$$
F(A) =\sum_{i=1}^C|A_i|^p
$$
其中，A为输入的特征图，C为输出张量中的通道数， F(A)为空间注意力激活特征图。

输出得到shape为（b, 1, w/r, h/r）的教师空间注意力激活特征图。



### 学生网络的注意力特征图的获取

学生注意力特征图使用一个空间注意力模块获取。

![](../figures/spacial_module.png)

​	

输入学生网络的中间层特征， 首先经过通道维度的最大池化和平均池化，然后将连接后的值，经过一个卷积

经过该模块后返回shape为(b, 1, w/r', h/r')的学生注意力特征图。



## 损失函数

### SR损失

像素级MSE



### 蒸馏损失计算

**1.激活空间注意力特征的知识蒸馏**

让学生注意力模块得到的空间注意力特征和教师网络的空间注意力激活特征尽可能相似。


$$
Q_T =
$$

$$
L_{AD}(Q_T,Q_S) = MSE(Q_T, Q_S)
$$





**2.相似性矩阵知识蒸馏 (batch_size大小的矩阵相乘)**

该方法不需考虑输入的特征图的尺寸。



**3.损失函数数量级问题，损失权重的设置**

1*MSE  , 1\*SD+1\*AD

sr loss:4198.17724609375
f_loss0: 0.03202895075082779  f_loss1: 2.9520325660705566
loss sum: tensor(4201.1611, device='cuda:0', grad_fn=<AddBackward>)





## 实验：

### 1.注意力蒸馏对原始超分网络RCAN的影响。

RCAN_dat, RCAN



#### 实验设计

~~1） 分别在相同的HR，LR图像对数据集上进行训练。~~

~~数据集：DIV2K~~

~~在相同测试集下比较SR 的指标，PSNR，SSIM。~~

~~2）在相同的文字图像数据集上进行训练。~~

 ~~数据集：textzoom~~

~~文字超分图像数据集上的SR指标比较。~~



两种模型分别在高法数据集上进行训练。







### 2.超分图片对文字检测效果的影响

用于文字检测的数据集

测试集 ICDAR(2013,2015,2017)数据集 或者MSRA-TD500，CTW-1500和TotalText数据集。

文字检测评价指标



#### 实验设计

**1）直接进行文字检测**

**2）经过作者给出的原始RCAN模型进行超分，然后进行文字检测**

**3）经过重新训练后的RCAN进行超分，然后进行文字检测**

经过DIV2K训练后的RCAN超分

经过textzoom训练后的RCAN超分

**4）经过重新训练后的RCAN_dat进行超分，然后进行文字检测****

经过DIV2K训练后的RCAN_dat 。。

经过textzoom训练后的RCAN_dat。。







实验操作步骤

1.

RCAN训练

```shell
python main.py --reset --chop --save_result --print_model
```



同样的参数，加入注意力蒸馏损失后，进行训练


